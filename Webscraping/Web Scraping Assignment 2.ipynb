{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85338725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af382d75",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6cc84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the naukri.com website on automated chrome window\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0f227ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding web element for search job bar\n",
    "search_job=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "search_job.send_keys('Data Analyst')\n",
    "    \n",
    "#Findind web element for search location bar\n",
    "search_loc=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_loc.send_keys('Bangalore')\n",
    "    \n",
    "#Clicking using class name function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "150754c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst - PLM Data Migration</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CGI</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Gurgaon/Gurugram</td>\n",
       "      <td>Groundtruth</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mobile Premier League (MPL)</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bsharp</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr. Data Analyst (SAS Data Management)</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi</td>\n",
       "      <td>NMS Consultant</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SVB Global Services India Llp</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0           Senior Data Analyst - PLM Data Migration   \n",
       "1                                       Data Analyst   \n",
       "2                                Senior Data Analyst   \n",
       "3                                  Lead Data Analyst   \n",
       "4  Contractual Hiring For Top MNC || Business Dat...   \n",
       "5            Master Data Management Business Analyst   \n",
       "6                                       Data Analyst   \n",
       "7             Sr. Data Analyst (SAS Data Management)   \n",
       "8                                  Lead Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                     Job Location  \\\n",
       "0                             Bangalore/Bengaluru   \n",
       "1                             Bangalore/Bengaluru   \n",
       "2  Hybrid - Bangalore/Bengaluru, Gurgaon/Gurugram   \n",
       "3                             Bangalore/Bengaluru   \n",
       "4                             Bangalore/Bengaluru   \n",
       "5                             Bangalore/Bengaluru   \n",
       "6                             Bangalore/Bengaluru   \n",
       "7                  Bangalore/Bengaluru, New Delhi   \n",
       "8                             Bangalore/Bengaluru   \n",
       "9                             Bangalore/Bengaluru   \n",
       "\n",
       "                    Company Name Experience  \n",
       "0                            CGI    3-6 Yrs  \n",
       "1                            IBM    3-4 Yrs  \n",
       "2                    Groundtruth    5-8 Yrs  \n",
       "3    Mobile Premier League (MPL)    4-7 Yrs  \n",
       "4                      TeamLease    5-8 Yrs  \n",
       "5                      Accenture    6-8 Yrs  \n",
       "6                         Bsharp    1-3 Yrs  \n",
       "7                 NMS Consultant   5-10 Yrs  \n",
       "8  SVB Global Services India Llp   8-13 Yrs  \n",
       "9                            IBM    3-4 Yrs  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making empty dataframe\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience=[]\n",
    "    \n",
    "#Extracting Job Titles\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "#Extracting Job Locations\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in location_tags[:10]:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "#Extracting Company Names\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "#Extracting Experience Required\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience.append(i.text)\n",
    "    \n",
    "    \n",
    "#Making Datframe\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Job Titles']=job_titles\n",
    "jobs['Job Location']=job_location\n",
    "jobs['Company Name']=company_name\n",
    "jobs['Experience']=experience\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70239f27",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1853ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the naukri.com website on automated chrome window\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0db59f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding web element for search job bar \n",
    "search_job=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "search_job.send_keys('Data Scientist')\n",
    "    \n",
    "#Findind web element for search location bar \n",
    "search_loc=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_loc.send_keys('Bangalore')\n",
    "    \n",
    "#Clicking using class name function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bcc9f7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>Citiustech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Altair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Quest Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>24 7 ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Looking For Immediate Joiners</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job Titles  \\\n",
       "0                  Analystics & Modeling Specialist   \n",
       "1                             Senior Data Scientist   \n",
       "2                  Assistant Manager - Data Science   \n",
       "3                                    Data Scientist   \n",
       "4                                    Data Scientist   \n",
       "5  ACN - Applied Intelligence - Data Scientist - 09   \n",
       "6                                Data Scientist - 2   \n",
       "7    Data Scientist - Looking For Immediate Joiners   \n",
       "8                             Senior Data Scientist   \n",
       "9                               Data Scientist - II   \n",
       "\n",
       "                                        Job Location             Company Name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "1        Hybrid - Bangalore/Bengaluru, Pune, Chennai                    Wipro  \n",
       "2         Hybrid - Bangalore/Bengaluru, Mumbai, Pune               Citiustech  \n",
       "3  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                   Altair  \n",
       "4                                Bangalore/Bengaluru             Quest Global  \n",
       "5                                Bangalore/Bengaluru                Accenture  \n",
       "6                                Bangalore/Bengaluru                  24 7 ai  \n",
       "7  Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...                    Wipro  \n",
       "8    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group  \n",
       "9     Bangalore/Bengaluru, India, Mumbai (All Areas)                  Bizongo  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making empty dataframe \n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "\n",
    "#Extracting Job Titles\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "#Extracting Job Locations\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in location_tags[:10]:\n",
    "    job_location.append(i.text)\n",
    "     \n",
    "#Extracting Company Names \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "#Making Datframe\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Job Titles']=job_titles\n",
    "jobs['Job Location']=job_location\n",
    "jobs['Company Name']=company_name\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c79d32",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "e1271318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the naukri.com website on automated chrome window\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "c7afa209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding web element for search job bar\n",
    "search_job=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "58677553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using class name function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "23ca9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the location filter by using absolute xpath function\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]')\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "b1453d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the salary filter by using absolute xpath function\n",
    "salary=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "2230fbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Chennai, Bangal...</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urgent hiring For Data Scientist (PHD Must Have)</td>\n",
       "      <td>Temp. WFH - Noida, Pune</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager - Data Science - Banking&amp;Financial Ser...</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Meon Technologies</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Alliance Recruitment Agency</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>RCPC</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Razor Group GmbH</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0                                     Data Scientist   \n",
       "1                    DigitalBCG GAMMA Data Scientist   \n",
       "2   Urgent hiring For Data Scientist (PHD Must Have)   \n",
       "3  Manager - Data Science - Banking&Financial Ser...   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                    Data Specialist   \n",
       "8                             Data scientist- Python   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Noida, Hyderabad/Secunderabad, Chennai, Bangal...   \n",
       "1                     New Delhi, Bangalore/Bengaluru   \n",
       "2                            Temp. WFH - Noida, Pune   \n",
       "3                   Delhi / NCR, Bangalore/Bengaluru   \n",
       "4  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "5                                              Noida   \n",
       "6                                              Noida   \n",
       "7                                              Noida   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                         Company Name Experience  \n",
       "0                             HCLTech    4-9 Yrs  \n",
       "1             Boston Consulting Group    2-5 Yrs  \n",
       "2                        NGI Ventures    0-4 Yrs  \n",
       "3                        Black Turtle    4-8 Yrs  \n",
       "4                torcai digital media    2-7 Yrs  \n",
       "5                   Meon Technologies    2-5 Yrs  \n",
       "6         Alliance Recruitment Agency    3-4 Yrs  \n",
       "7                                RCPC    4-6 Yrs  \n",
       "8  TeamPlus Staffing Solution Pvt Ltd    3-6 Yrs  \n",
       "9                    Razor Group GmbH    2-3 Yrs  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making empty datasets\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience=[]\n",
    "\n",
    "#Extracting Job titles\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)\n",
    "job_titles\n",
    "\n",
    "#Extracting Job Locations\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in location_tags[:10]:\n",
    "    job_location.append(i.text)\n",
    "job_location\n",
    "\n",
    "#Extracting Comapany Names\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company_name.append(i.text)\n",
    "company_name\n",
    "\n",
    "#Extracting Experience Required\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience.append(i.text)\n",
    "experience\n",
    "\n",
    "#Making Datframe\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Job Titles']=job_titles\n",
    "jobs['Job Location']=job_location\n",
    "jobs['Company Name']=company_name\n",
    "jobs['Experience']=experience\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb77c2",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8e2d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the naukri.com website on automated chrome window\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#Login credential from popped up, so closing it by using class name function\n",
    "close_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b12a9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding web element for searching bar\n",
    "search_sunglasses=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_sunglasses.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85ef25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using class name function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfca4dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RESIST EYEWEAR</td>\n",
       "      <td>Polarized, Riding Glasses, UV Protection Wayfa...</td>\n",
       "      <td>₹1,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARICKS</td>\n",
       "      <td>UV Protection, Polarized Rectangular Sunglasse...</td>\n",
       "      <td>₹236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (55)</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PROVOGUE</td>\n",
       "      <td>Polarized, UV Protection Rectangular Sunglasse...</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sewell</td>\n",
       "      <td>Mirrored, Night Vision, UV Protection, Riding ...</td>\n",
       "      <td>₹265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description   Price\n",
       "0   RESIST EYEWEAR  Polarized, Riding Glasses, UV Protection Wayfa...  ₹1,399\n",
       "1           ARICKS  UV Protection, Polarized Rectangular Sunglasse...    ₹236\n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹649\n",
       "3           PIRASO          UV Protection Rectangular Sunglasses (52)    ₹199\n",
       "4           SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...    ₹283\n",
       "..             ...                                                ...     ...\n",
       "95          PIRASO             UV Protection Wayfarer Sunglasses (55)    ₹251\n",
       "96       ROYAL SON     Polarized, UV Protection Round Sunglasses (55)    ₹664\n",
       "97        PROVOGUE  Polarized, UV Protection Rectangular Sunglasse...    ₹664\n",
       "98        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹679\n",
       "99          Sewell  Mirrored, Night Vision, UV Protection, Riding ...    ₹265\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Empty datasets\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "\n",
    "#Giving Page number start and end\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(0,1):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(0,1):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(0,1):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"] ')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(1,2):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(1,2):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(1,2):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"] ')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(2,3):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(2,3):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(2,3):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text)\n",
    "\n",
    "#Making DataFrame\n",
    "Sunglasses=pd.DataFrame()\n",
    "Sunglasses['Brand Name']=brand[:100]\n",
    "Sunglasses['Product Description']=product_description[:100]\n",
    "Sunglasses['Price']=price[:100]\n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da205bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3426ca04",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "96fd6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the naukri.com website on automated chrome window\n",
    "url='https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&q=i+phone&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=organic&iid=12abeb08-0079-49d7-a541-1683fd28f409.MOBFWQ6BXGJCEYNY.SEARCH&ppt=None&ppn=None&ssid=zy38ebgqsw0000001667476486195&qH=8de575501391c29c'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "20ee1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As only 3 reviews we can see, so clicking on all reviews button\n",
    "all_reviews=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div/span')\n",
    "all_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "9c588d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Empty datasets\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "#extracting rating from page 1 \n",
    "for page in range(0,1):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "#extracting review_summary from page 1\n",
    "for page in range(0,1):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting full review from page 1\n",
    "for page in range(0,1):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)\n",
    "#clicking on next button to go on next page\n",
    "\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[2]')\n",
    "next_button.click() \n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "13865b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating from page 2\n",
    "for page in range(1,2):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "#extracting review_summary from page 2\n",
    "for page in range(1,2):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting  full review  from page 2\n",
    "for page in range(1,2):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "3009f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "232390f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating from page 3\n",
    "for page in range(2,3):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "\n",
    "#extracting review_summary from page 3\n",
    "for page in range(2,3):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting  full review  from page 3\n",
    "for page in range(2,3):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8ec889c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[5]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "dd974220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating from page 4 \n",
    "for page in range(3,4):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "\n",
    "#extracting review_summary from page 4\n",
    "for page in range(3,4):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting  full review  from page 4\n",
    "for page in range(3,4):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "18e27aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[6]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "42c7baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating  from page 5 \n",
    "for page in range(4,5):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "#extracting review_summary from page 5\n",
    "for page in range(4,5):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting  full review  from page 5\n",
    "for page in range(4,5):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8eea9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d652faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating  from page 6 \n",
    "for page in range(5,6):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "#extracting review_summary from page 6\n",
    "for page in range(5,6):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting full review  from page 6\n",
    "for page in range(5,6):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "08a18299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "09b00eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating  from page 7 \n",
    "for page in range(6,7):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "#extracting review_summary from page 7\n",
    "for page in range(6,7):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting full review  from page 7\n",
    "for page in range(6,7):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "fa41bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b54a8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating  from page 8 \n",
    "for page in range(7,8):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "#extracting review_summary from page 8\n",
    "for page in range(7,8):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting  full review  from page 8\n",
    "for page in range(7,8):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7957db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6a6f1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating  from page 9\n",
    "for page in range(8,9):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "#extracting review_summary from page 9\n",
    "for page in range(8,9):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting  full review  from page 9\n",
    "for page in range(8,9):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "bc2b7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "79510201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting rating from page 10 \n",
    "for page in range(9,10):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "#extracting review_summary from page 10\n",
    "for page in range(9,10):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags:\n",
    "        review_summary.append(i.text)\n",
    "        \n",
    "#extracting full review from page 10\n",
    "for page in range(9,10):\n",
    "    full_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags:\n",
    "        full_review.append(i.text)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4201b8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanks Flipkart For this amazing deal! I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>A wort full value for money decision it’s . Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Dear friends... I want to share my experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>The best all rounder iphone. Flipkart is doing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Amazing phone and on great deal I received wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       4      Value-for-money   \n",
       "2       5     Perfect product!   \n",
       "3       5  Best in the market!   \n",
       "4       5   Highly recommended   \n",
       "..    ...                  ...   \n",
       "95      5   Highly recommended   \n",
       "96      5            Brilliant   \n",
       "97      5            Must buy!   \n",
       "98      5  Best in the market!   \n",
       "99      4            Brilliant   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   I'm Really happy with the product\\nDelivery wa...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   What a camera .....just awesome ..you can feel...  \n",
       "..                                                ...  \n",
       "95  Thanks Flipkart For this amazing deal! I had a...  \n",
       "96  A wort full value for money decision it’s . Si...  \n",
       "97  Dear friends... I want to share my experience ...  \n",
       "98  The best all rounder iphone. Flipkart is doing...  \n",
       "99  Amazing phone and on great deal I received wit...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone=pd.DataFrame()\n",
    "iphone['Rating']=rating[:100]\n",
    "iphone['Review Summary']=review_summary[:100]\n",
    "iphone['Full Review']=full_review[:100]\n",
    "iphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deecf9a",
   "metadata": {},
   "source": [
    "\n",
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06ac736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the naukri.com website on automated chrome window\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#Login credential from popped up, so closing it by using class name function\n",
    "close_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf3b8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding web element for searching bar\n",
    "search_sneakers=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_sneakers.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb418035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using class name function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "65d5bf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NXIN</td>\n",
       "      <td>Court Star Vulc FS Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Trinity Sneakers For Men</td>\n",
       "      <td>₹395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Acrux Sneakers For Men</td>\n",
       "      <td>₹329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Mesh | Ultralightweight | Comfortable | Breath...</td>\n",
       "      <td>₹2,063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Casual Sneakers For Men</td>\n",
       "      <td>₹1,709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name                                Product Description   Price\n",
       "0           NXIN                Court Star Vulc FS Sneakers For Men    ₹379\n",
       "1           PUMA                                   Sneakers For Men  ₹2,879\n",
       "2       RED TAPE                                   Sneakers For Men  ₹1,249\n",
       "3       RED TAPE                                   Sneakers For Men  ₹1,079\n",
       "4         Labbin                           Trinity Sneakers For Men    ₹395\n",
       "..           ...                                                ...     ...\n",
       "95  Robbie jones                             Acrux Sneakers For Men    ₹329\n",
       "96          PUMA  Mesh | Ultralightweight | Comfortable | Breath...  ₹2,063\n",
       "97          PUMA                            Casual Sneakers For Men  ₹1,709\n",
       "98      Magnolia  Original Luxury Branded Fashionable Men's Casu...    ₹299\n",
       "99     Deals4you                                   Sneakers For Men    ₹389\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Empty datasets\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "\n",
    "#Giving Page number start and end\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(0,1):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(0,1):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(0,1):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(1,2):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(1,2):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(1,2):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(2,3):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(2,3):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(2,3):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text)\n",
    "\n",
    "\n",
    "#Making DataFrame\n",
    "Sneakers=pd.DataFrame()\n",
    "Sneakers['Brand Name']=brand[:100]\n",
    "Sneakers['Product Description']=product_description[:100]\n",
    "Sneakers['Price']=price[:100]\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc03442",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image.\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step. : In Case, Inspect click don’t works, Please use ctrl+shift+c to inspect the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ebe9a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the naukri.com website on automated chrome window\n",
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13a6199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the color filter(black) by using absolute xpath function\n",
    "color_filter=driver.find_element(By.XPATH,'/html/body/div[2]/div/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1726ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the second price filter by using absolute xpath function\n",
    "price_filter=driver.find_element(By.XPATH,'/html/body/div[2]/div/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e3198d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>JORDAN MAX AURA 4 Shoes</td>\n",
       "      <td>Rs. 10165Rs. 11295(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Eternity Nitro Running Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>JORDAN ZION 2 Basketball Shoes</td>\n",
       "      <td>Rs. 9175Rs. 10795(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR SonicSE Running Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men ChargedEscape 3 BL Running</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD 15 Basketball Shoes</td>\n",
       "      <td>Rs. 11196Rs. 13995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Louis Philippe</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 7224Rs. 8499(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Textured Leather Sneakers</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>ZOOM FREAK 4 Basketball Shoes</td>\n",
       "      <td>Rs. 9600Rs. 11295(15% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name             Product Description  \\\n",
       "0             Nike         JORDAN MAX AURA 4 Shoes   \n",
       "1             Puma    Eternity Nitro Running Shoes   \n",
       "2             Nike  JORDAN ZION 2 Basketball Shoes   \n",
       "3     UNDER ARMOUR  Men HOVR SonicSE Running Shoes   \n",
       "4     UNDER ARMOUR  Men ChargedEscape 3 BL Running   \n",
       "..             ...                             ...   \n",
       "95            Nike      Men KD 15 Basketball Shoes   \n",
       "96         Bugatti               Men Walking Shoes   \n",
       "97  Louis Philippe     Men Leather Formal Slip-Ons   \n",
       "98         Bugatti   Men Textured Leather Sneakers   \n",
       "99            Nike   ZOOM FREAK 4 Basketball Shoes   \n",
       "\n",
       "                          Price  \n",
       "0   Rs. 10165Rs. 11295(10% OFF)  \n",
       "1                     Rs. 12999  \n",
       "2    Rs. 9175Rs. 10795(15% OFF)  \n",
       "3                      Rs. 9999  \n",
       "4                      Rs. 8999  \n",
       "..                          ...  \n",
       "95  Rs. 11196Rs. 13995(20% OFF)  \n",
       "96                     Rs. 9999  \n",
       "97    Rs. 7224Rs. 8499(15% OFF)  \n",
       "98                    Rs. 11999  \n",
       "99   Rs. 9600Rs. 11295(15% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Empty datasets\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "\n",
    "#Giving Page number start and end\n",
    "start=0\n",
    "end=2\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(0,1):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(0,1):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(0,1):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text.split('|')[0])\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting brand names from from different pages \n",
    "for page in range(1,2):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in brand_names:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "\n",
    "#extracting product description from from different pages         \n",
    "for page in range(1,2):\n",
    "    product_descr=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in product_descr:\n",
    "        product_description.append(i.text)\n",
    "\n",
    "#extracting prices from from different pages \n",
    "for page in range(1,2):\n",
    "    price_sun=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in price_sun:\n",
    "        price.append(i.text.split('|')[0])\n",
    "\n",
    "\n",
    "#Making DataFrame\n",
    "myntra_shoes=pd.DataFrame()\n",
    "myntra_shoes['Brand Name']=brand[:100]\n",
    "myntra_shoes['Product Description']=product_description[:100]\n",
    "myntra_shoes['Price']=price[:100]\n",
    "myntra_shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd428200",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048fcd6",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7d84c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the amazon.in website on automated chrome window\n",
    "url='https://www.amazon.in'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "fb9ab720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding web element for searching bar\n",
    "search_laptops=driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search_laptops.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "067b4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using class name function\n",
    "search_btn=driver.find_element(By.ID,\"nav-search-submit-button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "848e8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the cpu filter(intel core i7) by using absolute xpath function\n",
    "cpu_filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[5]/li[11]/span/a/span')\n",
    "cpu_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4f0ff01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making empty dataset\n",
    "title=[]\n",
    "price=[]\n",
    "ratings=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "dceda176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting titles\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "    \n",
    "#Extracting Price\n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f654d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating Ratings\n",
    "urls=driver.find_elements(By.XPATH,\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try: #exception handling for nosuchelementexception             \n",
    "        rate=driver.find_element(By.XPATH,\"//span[@id='acrCustomerReviewText']\")\n",
    "        rate.click()  #exception handling for nosuchelementexception  \n",
    "        ratingss=driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base']\")\n",
    "        for j in ratingss:\n",
    "            ratings.append(j.text)#appending the ratings\n",
    "            \n",
    "    except NoSuchElementException as e:\n",
    "        ratings.append(\"NO rating\")#appending the No rating if no rating is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "3743fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...</td>\n",
       "      <td>97,990</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 Pro Intel 12th Gen i7 Evo...</td>\n",
       "      <td>1,03,490</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>80,490</td>\n",
       "      <td>2.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>93,999</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>25,895</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td>83,990</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>84,918</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Inspiron 5320 Laptop, i7-1260P, 16GB LPDD...</td>\n",
       "      <td>25,990</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) HP Workstation Zbook Intel Core i7-4...</td>\n",
       "      <td>1,01,990</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td>86,490</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles     Price       Ratings\n",
       "0  Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...    97,990  3.9 out of 5\n",
       "1  Samsung Galaxy Book2 Pro Intel 12th Gen i7 Evo...  1,03,490  4.3 out of 5\n",
       "2  HP Pavilion x360 11th Gen Intel Core i7 14 inc...    80,490  2.1 out of 5\n",
       "3  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    93,999  4.1 out of 5\n",
       "4  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    25,895  4.1 out of 5\n",
       "5  (Renewed) HP ProBook 430 G3 6th Gen Intel Core...    83,990    4 out of 5\n",
       "6  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...    84,918    4 out of 5\n",
       "7  Dell Inspiron 5320 Laptop, i7-1260P, 16GB LPDD...    25,990  3.7 out of 5\n",
       "8  (Renewed) HP Workstation Zbook Intel Core i7-4...  1,01,990  3.7 out of 5\n",
       "9  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...    86,490  3.4 out of 5"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Dataframe\n",
    "laptops=pd.DataFrame()\n",
    "laptops['Titles']=title[:10]\n",
    "laptops['Price']=price[:10]\n",
    "laptops['Ratings']=ratings[:10]\n",
    "laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2370afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496829c8",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    " The above task will be done in following steps:\n",
    " 1.First get the webpage https://www.azquotes.com/\n",
    " 2. Click on Top Quotes\n",
    " 3. Than scrap a) Quote b) Author c) Type Of Quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d66f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the amazon.in website on automated chrome window\n",
    "url='https://www.azquotes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9bb35c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quote_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quote_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a397c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Type of Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>No matter how plain a woman may be, if truth a...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>Beauty, Beautiful, Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes             Authors  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  No matter how plain a woman may be, if truth a...   Eleanor Roosevelt   \n",
       "\n",
       "                               Type of Quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999                  Beauty, Beautiful, Truth  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making empty dataframe\n",
    "quote=[]\n",
    "author=[]\n",
    "type_of_quote=[]\n",
    "\n",
    "#Giving Page number start and end\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "#extracting quotes from page 1 \n",
    "for page in range(0,1):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 1\n",
    "for page in range(0,1):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote from page 1\n",
    "for page in range(0,1):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "        \n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes from page 2\n",
    "for page in range(1,2):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 2\n",
    "for page in range(1,2):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 2\n",
    "for page in range(1,2):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "        \n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes from page 3 \n",
    "for page in range(2,3):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 3\n",
    "for page in range(2,3):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 3\n",
    "for page in range(2,3):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "        \n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes from page 4 \n",
    "for page in range(3,4):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "\n",
    "#extracting authors from page 4\n",
    "for page in range(3,4):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 4\n",
    "for page in range(3,4):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "        \n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes  from page 5 \n",
    "for page in range(4,5):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 5\n",
    "for page in range(4,5):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 5\n",
    "for page in range(4,5):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes  from page 6 \n",
    "for page in range(5,6):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 6\n",
    "for page in range(5,6):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 6\n",
    "for page in range(5,6):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes  from page 7\n",
    "for page in range(6,7):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 7\n",
    "for page in range(6,7):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 7\n",
    "for page in range(6,7):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes from page 9 \n",
    "for page in range(7,8):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 8\n",
    "for page in range(7,8):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 8\n",
    "for page in range(7,8):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes from from page 9\n",
    "for page in range(8,9):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 9\n",
    "for page in range(8,9):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 9\n",
    "for page in range(8,9):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "\n",
    "#clicking on next button to go on next page        \n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]')\n",
    "next_button.click()\n",
    "\n",
    "#Sleep time for the browser while loading the data\n",
    "time.sleep(3)\n",
    "\n",
    "#extracting quotes from page 10\n",
    "for page in range(9,10):\n",
    "    quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote.append(i.text)\n",
    "        \n",
    "#extracting authors from page 10\n",
    "for page in range(9,10):\n",
    "    author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "        \n",
    "#extracting type of quote  from page 10\n",
    "for page in range(9,10):\n",
    "    type_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_tags:\n",
    "        type_of_quote.append(i.text)\n",
    "\n",
    "\n",
    "#Making DataFrame\n",
    "top_quotes=pd.DataFrame()\n",
    "top_quotes['Quotes']=quote\n",
    "top_quotes['Authors']=author\n",
    "top_quotes['Type of Quotes']=type_of_quote\n",
    "top_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbde7ac",
   "metadata": {},
   "source": [
    "# Q10: Write s python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "f574b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the amazon.in website on automated chrome window\n",
    "url='https://www.jagranjosh.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "64b13921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on GK option\n",
    "gk_btn=driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]/a')\n",
    "gk_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "70c8ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on list of prime minister\n",
    "list_primeministers=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "list_primeministers.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "ec42de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Empty datasets\n",
    "prime_min=[]\n",
    "born_dead=[]\n",
    "term=[]\n",
    "remarks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "5a2f6441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of first prime minister\n",
    "prime=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[2]')\n",
    "for i in prime:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "\n",
    "date=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[2]')\n",
    "for i in date:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[2]')\n",
    "for i in terms:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[2]')\n",
    "for i in remark:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "ab44c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 2nd prime minister\n",
    "prime=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[3]')\n",
    "for i in prime:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[3]')\n",
    "for i in date:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[3]')\n",
    "for i in terms:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[3]')\n",
    "for i in remark:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "02442bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 3rd prime minister\n",
    "prime=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[4]')\n",
    "for i in prime:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[4]')\n",
    "for i in date:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[4]')\n",
    "for i in terms:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[4]')\n",
    "for i in remark:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "47b1ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 4th prime minister\n",
    "prime=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[5]')\n",
    "for i in prime:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[5]')\n",
    "for i in date:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[5]')\n",
    "for i in terms:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[5]')\n",
    "for i in remark:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "a5babf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 5th prime minister\n",
    "prime=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[6]')\n",
    "for i in prime:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[6]')\n",
    "for i in date:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[6]')\n",
    "for i in terms:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[6]')\n",
    "for i in remark:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "07ad7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 6th prime minister\n",
    "prime=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[7]')\n",
    "for i in prime:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[7]')\n",
    "for i in date:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[7]')\n",
    "for i in terms:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark=drive.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[7]')\n",
    "for i in remark:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "3aceecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 7th prime minister\n",
    "prime7=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[8]')\n",
    "for i in prime7:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[8]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[8]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[8]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "6b21496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 8th prime minister\n",
    "prime8=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[9]')\n",
    "for i in prime8:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[9]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[9]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[9]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "1ded8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 9th prime minister\n",
    "prime9=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[10]')\n",
    "for i in prime9:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[10]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[10]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[10]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "c3ba6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 10th prime minister\n",
    "prime10=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[11]')\n",
    "for i in prime10:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[11]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[11]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[11]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "69ad9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 11th prime minister\n",
    "prime11=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[12]')\n",
    "for i in prime11:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[12]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[12]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[12]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "8a981bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 12th prime minister\n",
    "prime12=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[13]')\n",
    "for i in prime12:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[13]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[13]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[13]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "6d4fcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 13th prime minister\n",
    "prime13=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[14]')\n",
    "for i in prime13:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[14]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[14]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[14]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "8106a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 14th prime minister\n",
    "prime14=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[15]')\n",
    "for i in prime14:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[15]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[15]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[15]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "999cee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 15th prime minister\n",
    "prime15=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[16]')\n",
    "for i in prime15:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[16]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[16]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[16]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "46859789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 16th prime minister\n",
    "prime16=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[17]')\n",
    "for i in prime16:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[17]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[17]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[17]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "e6efe53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 17th prime minister\n",
    "prime17=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[18]')\n",
    "for i in prime17:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[18]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[18]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[18]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "524cf9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Name, born and dead year, term of office and remarks of 18th prime minister\n",
    "prime17=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[19]')\n",
    "for i in prime17:\n",
    "    prime_min.append(i.text.split('\\n')[1])\n",
    "    \n",
    "date1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[19]')\n",
    "for i in date1:\n",
    "    born_dead.append(i.text.split('\\n')[2])\n",
    "    \n",
    "terms1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[19]')\n",
    "for i in terms1:\n",
    "    term.append(i.text.split('\\n')[3])\n",
    "    \n",
    "remark1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[19]')\n",
    "for i in remark1:\n",
    "    remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "6bdf5832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                   Term  \\\n",
       "0         15 August 1947 to 27 May 1964   \n",
       "1           27 May 1964 to 9 June 1964,   \n",
       "2        9 June 1964 to 11 January 1966   \n",
       "3    11 January 1966 to 24 January 1966   \n",
       "4      24 January 1966 to 24 March 1977   \n",
       "5       24 March 1977 to  28 July 1979    \n",
       "6       28 July 1979 to 14 January 1980   \n",
       "7    14 January 1980 to 31 October 1984   \n",
       "8    31 October 1984 to 2 December 1989   \n",
       "9   2 December 1989 to 10 November 1990   \n",
       "10     10 November 1990 to 21 June 1991   \n",
       "11          21 June 1991 to 16 May 1996   \n",
       "12           16 May 1996 to 1 June 1996   \n",
       "13         1 June 1996 to 21 April 1997   \n",
       "14      21 April 1997 to 19 March 1998    \n",
       "15        19 March 1998 to 22 May 2004    \n",
       "16        22 May 2004 to 26 May 2014      \n",
       "17                26 May 2014 - Present   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Dataframe\n",
    "abc=pd.DataFrame()\n",
    "abc['Name']=prime_min\n",
    "abc['Born-Dead']=born_dead\n",
    "abc['Term']=term\n",
    "abc['Remarks']=remarks\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cadf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c3329",
   "metadata": {},
   "source": [
    "# Q11: Write s python program to display list of 50 Most expensive cars in the world (i.e. Company name, Model \n",
    "name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on left side.\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "53a2ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "#Maximizing the automated\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening the amazon.in website on automated chrome window\n",
    "url='https://www.motor1.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "415491b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on dropdown menu\n",
    "dropdown=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div[1]/div')\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "dab529a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on list\n",
    "list_btn=driver.find_element(By.XPATH,'/html/body/div[3]/div[1]/div[3]/ul/li[4]/a')\n",
    "list_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "49b277f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on expensive car\n",
    "expensive_car=driver.find_element(By.XPATH,'/html/body/div[2]/div[9]/div[1]/div[1]/div/div/div[1]/div/div[1]/h3/a')\n",
    "expensive_car.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "5f13f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making empty datasets\n",
    "name=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "d464d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Model and company names\n",
    "name_tags=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in name_tags:\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "8234ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Prices\n",
    "price_tags2=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[4]/strong')\n",
    "for i in price_tags2:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[6]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[8]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[10]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[12]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[14]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[16]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[18]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[20]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[22]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[24]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[26]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[28]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[30]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[32]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[34]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[36]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[38]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[40]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[42]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[44]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[46]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[48]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[50]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[52]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[54]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[56]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[58]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[60]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[62]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[64]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[66]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[68]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[70]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[72]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[74]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[76]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[78]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[80]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[82]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[84]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[86]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[88]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[90]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[92]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[94]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[96]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[98]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[100]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "price_tags=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[102]/strong')\n",
    "for i in price_tags:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "0ccf0cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company and Model Name</th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drako GTE</td>\n",
       "      <td>Price: $1.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company and Model Name                       Prices\n",
       "0                         Drako GTE          Price: $1.2 Million\n",
       "1                     De Tomaso P72          Price: $1.3 Million\n",
       "2                 Ferrari LaFerrari          Price: $1.4 Million\n",
       "3                     Pagani Huayra          Price: $1.4 Million\n",
       "4                      McLaren Elva          Price: $1.7 Million\n",
       "5                       Czinger 21C          Price: $1.7 Million\n",
       "6                     Ferrari Monza          Price: $1.7 Million\n",
       "7                Gordon Murray T.33          Price: $1.7 Million\n",
       "8                 Koenigsegg Gemera          Price: $1.7 Million\n",
       "9                       Zenvo TSR-S          Price: $1.7 Million\n",
       "10               Hennessey Venom F5          Price: $1.8 Million\n",
       "11                  Bentley Bacalar          Price: $1.9 Million\n",
       "12    Hispano Suiza Carmen Boulogne          Price: $1.9 Million\n",
       "13           Bentley Mulliner Batur          Price: $2.0 Million\n",
       "14                     Deus Vayanne          Price: $2.0 Million\n",
       "15                      SSC Tuatara         Price: $2.0 Million*\n",
       "16                      Lotus Evija          Price: $2.1 Million\n",
       "17              Aston Martin Vulcan          Price: $2.3 Million\n",
       "18                       Delage D12          Price: $2.3 Million\n",
       "19                McLaren Speedtail          Price: $2.3 Million\n",
       "20                     Rimac Nevera          Price: $2.4 Million\n",
       "21                    Pagani Utopia          Price: $2.5 Million\n",
       "22             Pininfarina Battista          Price: $2.5 Million\n",
       "23                Ferrari FXX K Evo          Price: $2.6 Million\n",
       "24               Gordon Murray T.50          Price: $2.6 Million\n",
       "25             Lamborghini Countach          Price: $2.6 Million\n",
       "26         Mercedes-AMG Project One          Price: $2.7 Million\n",
       "27              Aston Martin Victor          Price: $3.0 Million\n",
       "28      Hennessey Venom F5 Roadster                 $3.0 Million\n",
       "29                 Koenigsegg Jesko          Price: $3.0 Million\n",
       "30            Aston Martin Valkyrie          Price: $3.2 Million\n",
       "31        W Motors Lykan Hypersport          Price: $3.4 Million\n",
       "32                    McLaren Solus                 $3.5 Million\n",
       "33        Pagani Huayra Roadster BC          Price: $3.5 Million\n",
       "34         Bugatti Chiron Pur Sport          Price: $3.6 Million\n",
       "35                 Lamborghini Sian          Price: $3.6 million\n",
       "36                 Koenigsegg CC850          Price: $3.7 Million\n",
       "37  Bugatti Chiron Super Sport 300+          Price: $3.9 Million\n",
       "38               Lamborghini Veneno          Price: $4.5 Million\n",
       "39                   Bugatti Bolide          Price: $4.7 Million\n",
       "40                  Bugatti Mistral          Price: $5.0 Million\n",
       "41              Pagani Huayra Imola          Price: $5.4 Million\n",
       "42                     Bugatti Divo          Price: $5.8 Million\n",
       "43              SP Automotive Chaos          Price: $6.4 Million\n",
       "44                 Pagani Codalunga          Price: $7.4 Million\n",
       "45         Mercedes-Maybach Exelero          Price: $8.0 Million\n",
       "46               Bugatti Centodieci          Price: $9.0 Million\n",
       "47             Rolls-Royce Sweptail         Price: $12.8 Million\n",
       "48         Bugatti La Voiture Noire         Price: $13.4 Million\n",
       "49           Rolls-Royce Boat Tail*  Price: $28.0 Million (est.)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Dataframe\n",
    "cars=pd.DataFrame()\n",
    "cars['Company and Model Name']=name[:50]\n",
    "cars['Prices']=price\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff08028",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
